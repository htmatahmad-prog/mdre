#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ğŸ¤– AI Workspace Pro - Ø§Ù„Ù†Ø³Ø®Ø© Ø§Ù„Ù…Ø­Ø³Ù‘Ù†Ø©
Ù…Ø¹ Ø§Ù„Ù…Ø²ÙŠØ¯ Ù…Ù† Ø§Ù„Ù…ÙŠØ²Ø§Øª ÙˆØ§Ù„Ù†Ù…Ø§Ø°Ø¬
"""

import os
import sys
from openai import OpenAI
import google.generativeai as genai
from anthropic import Anthropic
import requests
import json
from pathlib import Path
import base64
from io import BytesIO

class AIWorkspacePro:
    """Ù…Ø³Ø§Ø­Ø© Ø¹Ù…Ù„ AI Ù…Ø­Ø³Ù‘Ù†Ø© Ù…Ø¹ Ù…ÙŠØ²Ø§Øª Ù…ØªÙ‚Ø¯Ù…Ø©"""

    def __init__(self):
        """ØªÙ‡ÙŠØ¦Ø© Ø¬Ù…ÙŠØ¹ Ø§Ù„Ù†Ù…Ø§Ø°Ø¬ ÙˆØ§Ù„Ù…ÙŠØ²Ø§Øª"""
        print("ğŸš€ Ø¬Ø§Ø±ÙŠ ØªØ­Ù…ÙŠÙ„ AI Workspace Pro...")

        self.load_keys()
        self.init_models()
        self.init_search()
        self.init_image_models()
        self.conversation = []
        self.current_model = None

        print("âœ… ØªÙ… Ø§Ù„ØªØ­Ù…ÙŠÙ„ Ø¨Ù†Ø¬Ø§Ø­!\n")

    def load_keys(self):
        """ØªØ­Ù…ÙŠÙ„ Ù…ÙØ§ØªÙŠØ­ API Ù…Ù† Ù…Ù„Ù Ø§Ù„Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø£Ùˆ Ù…ØªØºÙŠØ±Ø§Øª Ø§Ù„Ø¨ÙŠØ¦Ø©"""
        # Ù…Ø­Ø§ÙˆÙ„Ø© Ø§Ù„ØªØ­Ù…ÙŠÙ„ Ù…Ù† Ù…Ù„Ù Ø§Ù„Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø£ÙˆÙ„Ø§Ù‹
        config_file = Path.home() / "config_keys.json"
        keys = {}

        if config_file.exists():
            try:
                with open(config_file, 'r') as f:
                    keys = json.load(f)
                print("âœ… ØªÙ… ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù…ÙØ§ØªÙŠØ­ Ù…Ù† Ø§Ù„Ù…Ù„Ù Ø§Ù„Ù…Ø­ÙÙˆØ¸")
            except:
                pass

        # Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ù…ÙØ§ØªÙŠØ­ Ù…Ù† Ø§Ù„Ù…Ù„Ù Ø£Ùˆ Ù…ØªØºÙŠØ±Ø§Øª Ø§Ù„Ø¨ÙŠØ¦Ø©
        self.openai_key = keys.get('openai') or os.getenv('OPENAI_API_KEY')
        self.google_key = keys.get('google') or os.getenv('GOOGLE_API_KEY')
        self.anthropic_key = keys.get('anthropic') or os.getenv('ANTHROPIC_API_KEY')
        self.serper_key = keys.get('serper') or os.getenv('SERPER_API_KEY')
        self.tavily_key = keys.get('tavily') or os.getenv('TAVILY_API_KEY')
        self.elevenlabs_key = os.getenv('ELEVENLABS_API_KEY')
        self.replicate_key = os.getenv('REPLICATE_API_KEY')

        # Ø¥Ø°Ø§ Ù„Ù… ØªÙˆØ¬Ø¯ Ù…ÙØ§ØªÙŠØ­ØŒ Ø§Ø¹Ø±Ø¶ Ø±Ø³Ø§Ù„Ø©
        if not (self.openai_key or self.google_key or self.anthropic_key):
            print("\nâš ï¸  ØªØ­Ø°ÙŠØ±: Ù„Ù… ÙŠØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ù…ÙØ§ØªÙŠØ­ API!")
            print("   Ø´ØºÙ‘Ù„: python3 setup_keys.py  Ù„Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ù„Ù…ÙØ§ØªÙŠØ­\n")

    def init_models(self):
        """ØªÙ‡ÙŠØ¦Ø© Ø¬Ù…ÙŠØ¹ Ø§Ù„Ù†Ù…Ø§Ø°Ø¬"""
        self.models = {}

        # OpenAI Models
        if self.openai_key:
            self.openai_client = OpenAI(api_key=self.openai_key)
            self.models.update({
                'gpt-4': {'name': 'GPT-4', 'client': 'openai', 'desc': 'ğŸ§  Ø§Ù„Ø£Ù‚ÙˆÙ‰ - Ù„Ù„Ù…Ù‡Ø§Ù… Ø§Ù„Ù…Ø¹Ù‚Ø¯Ø©'},
                'gpt-4-turbo': {'name': 'GPT-4 Turbo', 'client': 'openai', 'desc': 'âš¡ Ø³Ø±ÙŠØ¹ ÙˆÙ‚ÙˆÙŠ'},
                'gpt-4o': {'name': 'GPT-4o', 'client': 'openai', 'desc': 'ğŸ¯ Ø§Ù„Ø£Ø­Ø¯Ø« Ù…Ù† OpenAI'},
                'gpt-3.5-turbo': {'name': 'GPT-3.5 Turbo', 'client': 'openai', 'desc': 'ğŸ’¨ Ø³Ø±ÙŠØ¹ ÙˆØ±Ø®ÙŠØµ'},
            })

        # Google Models
        if self.google_key:
            genai.configure(api_key=self.google_key)
            self.models.update({
                'gemini-pro': {'name': 'Gemini Pro', 'client': 'google', 'desc': 'ğŸŒŸ Ù‚ÙˆÙŠ ÙˆÙ…ØªØ¹Ø¯Ø¯ Ø§Ù„ÙˆØ³Ø§Ø¦Ø·'},
                'gemini-1.5-pro': {'name': 'Gemini 1.5 Pro', 'client': 'google', 'desc': 'ğŸš€ Ø§Ù„Ø£Ø­Ø¯Ø« ÙˆØ§Ù„Ø£Ù‚ÙˆÙ‰'},
                'gemini-1.5-flash': {'name': 'Gemini 1.5 Flash', 'client': 'google', 'desc': 'âš¡ Ø³Ø±ÙŠØ¹ Ø¬Ø¯Ø§Ù‹'},
            })

        # Anthropic Models
        if self.anthropic_key:
            self.claude_client = Anthropic(api_key=self.anthropic_key)
            self.models.update({
                'claude-3-opus-20240229': {'name': 'Claude 3 Opus', 'client': 'anthropic', 'desc': 'ğŸ‘‘ Ø§Ù„Ø£Ø°ÙƒÙ‰'},
                'claude-3-5-sonnet-20241022': {'name': 'Claude 3.5 Sonnet', 'client': 'anthropic', 'desc': 'â­ Ù…ØªÙˆØ§Ø²Ù† ÙˆÙ…ØªØ·ÙˆØ±'},
                'claude-3-haiku-20240307': {'name': 'Claude 3 Haiku', 'client': 'anthropic', 'desc': 'ğŸ’¨ Ø³Ø±ÙŠØ¹ ÙˆÙØ¹Ø§Ù„'},
            })

    def init_search(self):
        """ØªÙ‡ÙŠØ¦Ø© Ù…Ø­Ø±ÙƒØ§Øª Ø§Ù„Ø¨Ø­Ø«"""
        self.search_engines = {}
        if self.serper_key:
            self.search_engines['serper'] = True
        if self.tavily_key:
            self.search_engines['tavily'] = True

    def init_image_models(self):
        """ØªÙ‡ÙŠØ¦Ø© Ù†Ù…Ø§Ø°Ø¬ Ø§Ù„ØµÙˆØ±"""
        self.image_models = {}

        if self.openai_key:
            self.image_models['dall-e-3'] = {
                'name': 'DALL-E 3',
                'desc': 'ØªÙˆÙ„ÙŠØ¯ ØµÙˆØ± Ø¹Ø§Ù„ÙŠØ© Ø§Ù„Ø¬ÙˆØ¯Ø©'
            }
            self.image_models['dall-e-2'] = {
                'name': 'DALL-E 2',
                'desc': 'ØªÙˆÙ„ÙŠØ¯ ØµÙˆØ± Ø³Ø±ÙŠØ¹'
            }

    def show_models(self):
        """Ø¹Ø±Ø¶ Ø§Ù„Ù†Ù…Ø§Ø°Ø¬ Ø§Ù„Ù…ØªØ§Ø­Ø©"""
        print("\n" + "="*70)
        print("ğŸ“‹ Ø§Ù„Ù†Ù…Ø§Ø°Ø¬ Ø§Ù„Ù…ØªØ§Ø­Ø© Ù„Ù„Ø¯Ø±Ø¯Ø´Ø©:")
        print("="*70)

        for i, (model_id, info) in enumerate(self.models.items(), 1):
            print(f"{i:2d}. {info['name']:<25} - {info['desc']}")

        print("\n" + "="*70)
        print("ğŸ¨ Ù†Ù…Ø§Ø°Ø¬ ØªÙˆÙ„ÙŠØ¯ Ø§Ù„ØµÙˆØ±:")
        print("="*70)

        for model_id, info in self.image_models.items():
            print(f"  â€¢ {info['name']:<25} - {info['desc']}")

        print()

    def select_model(self):
        """Ø§Ø®ØªÙŠØ§Ø± Ø§Ù„Ù†Ù…ÙˆØ°Ø¬"""
        self.show_models()

        while True:
            choice = input("Ø§Ø®ØªØ± Ø±Ù‚Ù… Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ (Ø£Ùˆ Ø§ÙƒØªØ¨ ID): ").strip()

            if choice.isdigit():
                idx = int(choice) - 1
                models_list = list(self.models.keys())
                if 0 <= idx < len(models_list):
                    self.current_model = models_list[idx]
                    print(f"\nâœ… ØªÙ… Ø§Ø®ØªÙŠØ§Ø±: {self.models[self.current_model]['name']}\n")
                    return

            elif choice in self.models:
                self.current_model = choice
                print(f"\nâœ… ØªÙ… Ø§Ø®ØªÙŠØ§Ø±: {self.models[self.current_model]['name']}\n")
                return

            print("âŒ Ø§Ø®ØªÙŠØ§Ø± ØºÙŠØ± ØµØ­ÙŠØ­ØŒ Ø­Ø§ÙˆÙ„ Ù…Ø±Ø© Ø£Ø®Ø±Ù‰")

    def chat(self, message, use_search=False, stream=False):
        """Ø§Ù„Ø¯Ø±Ø¯Ø´Ø© Ù…Ø¹ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬"""
        if not self.current_model:
            print("âŒ Ù„Ù… ÙŠØªÙ… Ø§Ø®ØªÙŠØ§Ø± Ù†Ù…ÙˆØ°Ø¬!")
            return None

        # Ø¥Ø¶Ø§ÙØ© Ù†ØªØ§Ø¦Ø¬ Ø§Ù„Ø¨Ø­Ø«
        if use_search:
            search_results = self.search(message)
            if search_results:
                message = f"{message}\n\nÙ†ØªØ§Ø¦Ø¬ Ø§Ù„Ø¨Ø­Ø«:\n{search_results}"

        model_info = self.models[self.current_model]
        client_type = model_info['client']

        try:
            # OpenAI
            if client_type == 'openai':
                if stream:
                    return self._chat_openai_stream(message)
                else:
                    response = self.openai_client.chat.completions.create(
                        model=self.current_model,
                        messages=[{"role": "user", "content": message}]
                    )
                    return response.choices[0].message.content

            # Google Gemini
            elif client_type == 'google':
                model = genai.GenerativeModel(self.current_model)
                if stream:
                    return self._chat_gemini_stream(model, message)
                else:
                    response = model.generate_content(message)
                    return response.text

            # Anthropic Claude
            elif client_type == 'anthropic':
                if stream:
                    return self._chat_claude_stream(message)
                else:
                    response = self.claude_client.messages.create(
                        model=self.current_model,
                        max_tokens=4096,
                        messages=[{"role": "user", "content": message}]
                    )
                    return response.content[0].text

        except Exception as e:
            return f"âŒ Ø®Ø·Ø£: {str(e)}"

    def _chat_openai_stream(self, message):
        """Ø¯Ø±Ø¯Ø´Ø© OpenAI Ù…Ø¹ streaming"""
        print(f"\nğŸ¤– {self.models[self.current_model]['name']}: ", end='', flush=True)

        stream = self.openai_client.chat.completions.create(
            model=self.current_model,
            messages=[{"role": "user", "content": message}],
            stream=True
        )

        full_response = ""
        for chunk in stream:
            if chunk.choices[0].delta.content:
                content = chunk.choices[0].delta.content
                print(content, end='', flush=True)
                full_response += content

        print()  # newline
        return full_response

    def _chat_gemini_stream(self, model, message):
        """Ø¯Ø±Ø¯Ø´Ø© Gemini Ù…Ø¹ streaming"""
        print(f"\nğŸ¤– {self.models[self.current_model]['name']}: ", end='', flush=True)

        response = model.generate_content(message, stream=True)

        full_response = ""
        for chunk in response:
            if chunk.text:
                print(chunk.text, end='', flush=True)
                full_response += chunk.text

        print()
        return full_response

    def _chat_claude_stream(self, message):
        """Ø¯Ø±Ø¯Ø´Ø© Claude Ù…Ø¹ streaming"""
        print(f"\nğŸ¤– {self.models[self.current_model]['name']}: ", end='', flush=True)

        full_response = ""
        with self.claude_client.messages.stream(
            model=self.current_model,
            max_tokens=4096,
            messages=[{"role": "user", "content": message}]
        ) as stream:
            for text in stream.text_stream:
                print(text, end='', flush=True)
                full_response += text

        print()
        return full_response

    def search(self, query):
        """Ø§Ù„Ø¨Ø­Ø« ÙÙŠ Ø§Ù„Ø¥Ù†ØªØ±Ù†Øª"""
        results = []

        # Serper
        if 'serper' in self.search_engines:
            try:
                url = "https://google.serper.dev/search"
                headers = {
                    'X-API-KEY': self.serper_key,
                    'Content-Type': 'application/json'
                }
                response = requests.post(url, headers=headers, json={'q': query}, timeout=10)
                data = response.json()

                for item in data.get('organic', [])[:5]:
                    results.append(f"ğŸ“„ {item['title']}\n   {item['snippet']}\n   ğŸ”— {item['link']}")
            except:
                pass

        # Tavily
        if 'tavily' in self.search_engines and not results:
            try:
                from tavily import TavilyClient
                client = TavilyClient(api_key=self.tavily_key)
                response = client.search(query, max_results=5)

                for item in response.get('results', []):
                    results.append(f"ğŸ“„ {item['title']}\n   {item['content'][:200]}...\n   ğŸ”— {item['url']}")
            except:
                pass

        return "\n\n".join(results) if results else None

    def generate_image(self, prompt, model='dall-e-3', size='1024x1024'):
        """ØªÙˆÙ„ÙŠØ¯ ØµÙˆØ±Ø©"""
        if not self.openai_key:
            return "âŒ Ù…ÙØªØ§Ø­ OpenAI ØºÙŠØ± Ù…ØªÙˆÙØ±"

        try:
            print(f"ğŸ¨ Ø¬Ø§Ø±ÙŠ ØªÙˆÙ„ÙŠØ¯ Ø§Ù„ØµÙˆØ±Ø©...")

            response = self.openai_client.images.generate(
                model=model,
                prompt=prompt,
                size=size,
                quality="standard" if model == "dall-e-2" else "hd",
                n=1,
            )

            image_url = response.data[0].url

            # Ø­ÙØ¸ Ø§Ù„ØµÙˆØ±Ø©
            img_response = requests.get(image_url)
            filename = f"generated_image_{hash(prompt)}.png"

            with open(filename, 'wb') as f:
                f.write(img_response.content)

            return f"âœ… ØªÙ… ØªÙˆÙ„ÙŠØ¯ Ø§Ù„ØµÙˆØ±Ø©: {filename}\nğŸ”— {image_url}"

        except Exception as e:
            return f"âŒ Ø®Ø·Ø£: {str(e)}"

    def text_to_speech(self, text, voice='alloy'):
        """ØªØ­ÙˆÙŠÙ„ Ù†Øµ Ù„ÙƒÙ„Ø§Ù…"""
        if not self.openai_key:
            return "âŒ Ù…ÙØªØ§Ø­ OpenAI ØºÙŠØ± Ù…ØªÙˆÙØ±"

        try:
            print(f"ğŸ”Š Ø¬Ø§Ø±ÙŠ ØªØ­ÙˆÙŠÙ„ Ø§Ù„Ù†Øµ Ù„ÙƒÙ„Ø§Ù…...")

            response = self.openai_client.audio.speech.create(
                model="tts-1",
                voice=voice,
                input=text
            )

            filename = f"speech_{hash(text)}.mp3"
            response.stream_to_file(filename)

            return f"âœ… ØªÙ… Ø­ÙØ¸ Ø§Ù„Ù…Ù„Ù Ø§Ù„ØµÙˆØªÙŠ: {filename}"

        except Exception as e:
            return f"âŒ Ø®Ø·Ø£: {str(e)}"

    def analyze_image(self, image_path, question="ØµÙ Ù‡Ø°Ù‡ Ø§Ù„ØµÙˆØ±Ø©"):
        """ØªØ­Ù„ÙŠÙ„ ØµÙˆØ±Ø©"""
        if not self.openai_key:
            return "âŒ Ù…ÙØªØ§Ø­ OpenAI ØºÙŠØ± Ù…ØªÙˆÙØ±"

        try:
            print(f"ğŸ” Ø¬Ø§Ø±ÙŠ ØªØ­Ù„ÙŠÙ„ Ø§Ù„ØµÙˆØ±Ø©...")

            # Ù‚Ø±Ø§Ø¡Ø© Ø§Ù„ØµÙˆØ±Ø©
            with open(image_path, "rb") as image_file:
                base64_image = base64.b64encode(image_file.read()).decode('utf-8')

            response = self.openai_client.chat.completions.create(
                model="gpt-4o",
                messages=[
                    {
                        "role": "user",
                        "content": [
                            {"type": "text", "text": question},
                            {
                                "type": "image_url",
                                "image_url": {
                                    "url": f"data:image/jpeg;base64,{base64_image}"
                                }
                            }
                        ]
                    }
                ],
                max_tokens=1000
            )

            return response.choices[0].message.content

        except Exception as e:
            return f"âŒ Ø®Ø·Ø£: {str(e)}"

    def read_file(self, file_path):
        """Ù‚Ø±Ø§Ø¡Ø© Ù…Ù„Ù"""
        try:
            path = Path(file_path)
            if not path.exists():
                return f"âŒ Ø§Ù„Ù…Ù„Ù ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯: {file_path}"

            with open(path, 'r', encoding='utf-8') as f:
                content = f.read()

            return content
        except Exception as e:
            return f"âŒ Ø®Ø·Ø£: {str(e)}"

    def write_file(self, file_path, content):
        """ÙƒØªØ§Ø¨Ø© Ù…Ù„Ù"""
        try:
            path = Path(file_path)
            path.parent.mkdir(parents=True, exist_ok=True)

            with open(path, 'w', encoding='utf-8') as f:
                f.write(content)

            return f"âœ… ØªÙ… Ø­ÙØ¸ Ø§Ù„Ù…Ù„Ù: {file_path}"
        except Exception as e:
            return f"âŒ Ø®Ø·Ø£: {str(e)}"

    def analyze_code(self, file_path):
        """ØªØ­Ù„ÙŠÙ„ ÙƒÙˆØ¯"""
        content = self.read_file(file_path)
        if content.startswith("âŒ"):
            return content

        prompt = f"""Ø­Ù„Ù„ Ù‡Ø°Ø§ Ø§Ù„ÙƒÙˆØ¯ Ø¨Ø´ÙƒÙ„ Ø´Ø§Ù…Ù„:

1. Ù…Ù„Ø®Øµ Ø¹Ù† ÙˆØ¸ÙŠÙØ© Ø§Ù„ÙƒÙˆØ¯
2. Ø§Ù„Ù…Ø´Ø§ÙƒÙ„ ÙˆØ§Ù„Ø£Ø®Ø·Ø§Ø¡ Ø§Ù„Ù…Ø­ØªÙ…Ù„Ø©
3. Ø§Ù‚ØªØ±Ø§Ø­Ø§Øª Ù„Ù„ØªØ­Ø³ÙŠÙ†
4. Ø£ÙØ¶Ù„ Ø§Ù„Ù…Ù…Ø§Ø±Ø³Ø§Øª

Ø§Ù„ÙƒÙˆØ¯:
```
{content}
```
"""
        return self.chat(prompt)

    def edit_code(self, file_path, instruction):
        """ØªØ¹Ø¯ÙŠÙ„ ÙƒÙˆØ¯"""
        content = self.read_file(file_path)
        if content.startswith("âŒ"):
            return content

        prompt = f"""Ø¹Ø¯Ù‘Ù„ Ù‡Ø°Ø§ Ø§Ù„ÙƒÙˆØ¯ Ø­Ø³Ø¨ Ø§Ù„ØªØ¹Ù„ÙŠÙ…Ø§Øª Ø§Ù„ØªØ§Ù„ÙŠØ©:
{instruction}

Ø§Ù„ÙƒÙˆØ¯ Ø§Ù„Ø­Ø§Ù„ÙŠ:
```
{content}
```

Ø£Ø¹Ø·Ù†ÙŠ Ø§Ù„ÙƒÙˆØ¯ Ø§Ù„Ù…Ø¹Ø¯Ù‘Ù„ ÙÙ‚Ø·ØŒ Ø¨Ø¯ÙˆÙ† Ø´Ø±Ø­ Ø¥Ø¶Ø§ÙÙŠ.
"""

        new_code = self.chat(prompt)

        # Ø­ÙØ¸ Ù†Ø³Ø®Ø© Ø§Ø­ØªÙŠØ§Ø·ÙŠØ©
        backup_path = f"{file_path}.backup"
        self.write_file(backup_path, content)

        # Ø­ÙØ¸ Ø§Ù„ÙƒÙˆØ¯ Ø§Ù„Ø¬Ø¯ÙŠØ¯
        result = self.write_file(file_path, new_code)
        return f"{result}\nâœ… Ù†Ø³Ø®Ø© Ø§Ø­ØªÙŠØ§Ø·ÙŠØ©: {backup_path}"

    def compare_models(self, question):
        """Ù…Ù‚Ø§Ø±Ù†Ø© Ø¥Ø¬Ø§Ø¨Ø§Øª Ø§Ù„Ù†Ù…Ø§Ø°Ø¬ Ø§Ù„Ù…Ø®ØªÙ„ÙØ©"""
        print("\n" + "="*70)
        print("ğŸ”„ Ø¬Ø§Ø±ÙŠ Ø§Ù„Ù…Ù‚Ø§Ø±Ù†Ø© Ø¨ÙŠÙ† Ø§Ù„Ù†Ù…Ø§Ø°Ø¬...")
        print("="*70 + "\n")

        original_model = self.current_model
        results = {}

        # Ø¬Ø±Ø¨ Ù…Ø¹ ÙƒÙ„ Ù†Ù…ÙˆØ°Ø¬
        for model_id, info in list(self.models.items())[:3]:  # Ø£ÙˆÙ„ 3 Ù†Ù…Ø§Ø°Ø¬
            self.current_model = model_id
            print(f"â³ {info['name']}...")

            response = self.chat(question)
            results[info['name']] = response

        # Ø¹Ø±Ø¶ Ø§Ù„Ù†ØªØ§Ø¦Ø¬
        print("\n" + "="*70)
        print("ğŸ“Š Ø§Ù„Ù†ØªØ§Ø¦Ø¬:")
        print("="*70 + "\n")

        for model_name, response in results.items():
            print(f"ğŸ¤– {model_name}:")
            print(f"{response[:200]}...")
            print("\n" + "-"*70 + "\n")

        # Ø¥Ø±Ø¬Ø§Ø¹ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ø£ØµÙ„ÙŠ
        self.current_model = original_model

    def interactive_mode(self):
        """Ø§Ù„ÙˆØ¶Ø¹ Ø§Ù„ØªÙØ§Ø¹Ù„ÙŠ Ø§Ù„Ù…Ø­Ø³Ù‘Ù†"""
        print("\n" + "="*70)
        print("ğŸ¤– Ù…Ø±Ø­Ø¨Ø§Ù‹ ÙÙŠ AI Workspace Pro - Ø§Ù„Ù†Ø³Ø®Ø© Ø§Ù„Ù…Ø­Ø³Ù‘Ù†Ø©")
        print("="*70)
        print("""
âœ¨ Ø§Ù„Ù…ÙŠØ²Ø§Øª Ø§Ù„Ø¬Ø¯ÙŠØ¯Ø©:
  /image      - ØªÙˆÙ„ÙŠØ¯ ØµÙˆØ±Ø© Ø¨Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ
  /vision     - ØªØ­Ù„ÙŠÙ„ ØµÙˆØ±Ø©
  /voice      - ØªØ­ÙˆÙŠÙ„ Ù†Øµ Ù„ÙƒÙ„Ø§Ù…
  /compare    - Ù…Ù‚Ø§Ø±Ù†Ø© Ø¥Ø¬Ø§Ø¨Ø§Øª Ø§Ù„Ù†Ù…Ø§Ø°Ø¬
  /stream     - Ø¯Ø±Ø¯Ø´Ø© Ù…Ø¹ Ø¹Ø±Ø¶ Ù…Ø¨Ø§Ø´Ø±

ğŸ“‹ Ø§Ù„Ø£ÙˆØ§Ù…Ø± Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ©:
  /models     - Ø§Ø®ØªÙŠØ§Ø± Ø§Ù„Ù†Ù…ÙˆØ°Ø¬
  /search     - Ø§Ù„Ø¨Ø­Ø« ÙÙŠ Ø§Ù„Ø¥Ù†ØªØ±Ù†Øª
  /read       - Ù‚Ø±Ø§Ø¡Ø© Ù…Ù„Ù
  /write      - ÙƒØªØ§Ø¨Ø© Ù…Ù„Ù
  /analyze    - ØªØ­Ù„ÙŠÙ„ ÙƒÙˆØ¯
  /edit       - ØªØ¹Ø¯ÙŠÙ„ ÙƒÙˆØ¯
  /help       - Ø§Ù„Ù…Ø³Ø§Ø¹Ø¯Ø©
  /exit       - Ø®Ø±ÙˆØ¬

ğŸ’¡ Ù†ØµÙŠØ­Ø©: Ø§ÙƒØªØ¨ Ø³Ø¤Ø§Ù„Ùƒ Ù…Ø¨Ø§Ø´Ø±Ø© Ù„Ù„Ø¯Ø±Ø¯Ø´Ø©!
""")

        # Ø§Ø®ØªÙŠØ§Ø± Ø§Ù„Ù†Ù…ÙˆØ°Ø¬
        self.select_model()

        while True:
            try:
                user_input = input("\nğŸ’¬ Ø£Ù†Øª: ").strip()

                if not user_input:
                    continue

                # Ø§Ù„Ø£ÙˆØ§Ù…Ø±
                if user_input.startswith('/'):
                    cmd = user_input.split()[0].lower()

                    if cmd == '/exit':
                        print("\nğŸ‘‹ Ø¥Ù„Ù‰ Ø§Ù„Ù„Ù‚Ø§Ø¡!")
                        break

                    elif cmd == '/models':
                        self.select_model()

                    elif cmd == '/search':
                        query = input("ğŸ” Ù…Ø§ ØªØ±ÙŠØ¯ Ø§Ù„Ø¨Ø­Ø« Ø¹Ù†Ù‡ØŸ ")
                        print("\nâ³ Ø¬Ø§Ø±ÙŠ Ø§Ù„Ø¨Ø­Ø«...")
                        results = self.search(query)
                        if results:
                            print(f"\nğŸ“Š Ù†ØªØ§Ø¦Ø¬ Ø§Ù„Ø¨Ø­Ø«:\n\n{results}")
                        else:
                            print("âŒ Ù„Ù… ÙŠØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ù†ØªØ§Ø¦Ø¬")

                    elif cmd == '/image':
                        prompt = input("ğŸ¨ ØµÙ Ø§Ù„ØµÙˆØ±Ø© Ø§Ù„ØªÙŠ ØªØ±ÙŠØ¯Ù‡Ø§: ")
                        result = self.generate_image(prompt)
                        print(f"\n{result}")

                    elif cmd == '/vision':
                        image_path = input("ğŸ“· Ù…Ø³Ø§Ø± Ø§Ù„ØµÙˆØ±Ø©: ")
                        question = input("â“ Ù…Ø§Ø°Ø§ ØªØ±ÙŠØ¯ Ø£Ù† ØªØ¹Ø±Ù Ø¹Ù† Ø§Ù„ØµÙˆØ±Ø©ØŸ (Ø§Ø¶ØºØ· Enter Ù„Ù„ÙˆØµÙ Ø§Ù„Ø¹Ø§Ù…): ")
                        if not question:
                            question = "ØµÙ Ù‡Ø°Ù‡ Ø§Ù„ØµÙˆØ±Ø© Ø¨Ø§Ù„ØªÙØµÙŠÙ„"
                        result = self.analyze_image(image_path, question)
                        print(f"\nğŸ” Ø§Ù„ØªØ­Ù„ÙŠÙ„:\n{result}")

                    elif cmd == '/voice':
                        text = input("ğŸ“ Ø§Ù„Ù†Øµ Ø§Ù„Ù…Ø±Ø§Ø¯ ØªØ­ÙˆÙŠÙ„Ù‡: ")
                        voice = input("ğŸ™ï¸ Ø§Ù„ØµÙˆØª (alloy/echo/fable/onyx/nova/shimmer) [Enter=alloy]: ").strip() or 'alloy'
                        result = self.text_to_speech(text, voice)
                        print(f"\n{result}")

                    elif cmd == '/compare':
                        question = input("â“ Ø§Ù„Ø³Ø¤Ø§Ù„ Ù„Ù„Ù…Ù‚Ø§Ø±Ù†Ø©: ")
                        self.compare_models(question)

                    elif cmd == '/stream':
                        message = input("ğŸ’¬ Ø±Ø³Ø§Ù„ØªÙƒ: ")
                        self.chat(message, stream=True)

                    elif cmd == '/read':
                        file_path = input("ğŸ“„ Ø§Ø³Ù… Ø§Ù„Ù…Ù„Ù: ")
                        content = self.read_file(file_path)
                        print(f"\nğŸ“„ Ø§Ù„Ù…Ø­ØªÙˆÙ‰:\n{content[:1000]}{'...' if len(content) > 1000 else ''}")

                    elif cmd == '/write':
                        file_path = input("ğŸ“„ Ø§Ø³Ù… Ø§Ù„Ù…Ù„Ù: ")
                        print("ğŸ“ Ø§ÙƒØªØ¨ Ø§Ù„Ù…Ø­ØªÙˆÙ‰ (Enter Ø«Ù… Ctrl+D Ù„Ù„Ø¥Ù†Ù‡Ø§Ø¡):")
                        lines = []
                        try:
                            while True:
                                lines.append(input())
                        except EOFError:
                            pass
                        content = "\n".join(lines)
                        result = self.write_file(file_path, content)
                        print(f"\n{result}")

                    elif cmd == '/analyze':
                        file_path = input("ğŸ“„ Ù…Ù„Ù Ø§Ù„ÙƒÙˆØ¯: ")
                        print("\nâ³ Ø¬Ø§Ø±ÙŠ Ø§Ù„ØªØ­Ù„ÙŠÙ„...")
                        result = self.analyze_code(file_path)
                        print(f"\nğŸ“Š Ø§Ù„ØªØ­Ù„ÙŠÙ„:\n{result}")

                    elif cmd == '/edit':
                        file_path = input("ğŸ“„ Ù…Ù„Ù Ø§Ù„ÙƒÙˆØ¯: ")
                        instruction = input("ğŸ“ Ù…Ø§Ø°Ø§ ØªØ±ÙŠØ¯ ØªØ¹Ø¯ÙŠÙ„Ù‡ØŸ ")
                        print("\nâ³ Ø¬Ø§Ø±ÙŠ Ø§Ù„ØªØ¹Ø¯ÙŠÙ„...")
                        result = self.edit_code(file_path, instruction)
                        print(f"\n{result}")

                    elif cmd == '/help':
                        print("""
ğŸ†˜ Ø¯Ù„ÙŠÙ„ Ø§Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù…:

âœ¨ Ù…ÙŠØ²Ø§Øª Ø¬Ø¯ÙŠØ¯Ø©:
  /image      - ØªÙˆÙ„ÙŠØ¯ ØµÙˆØ±Ø© (DALL-E 3)
  /vision     - ØªØ­Ù„ÙŠÙ„ ØµÙˆØ±Ø© (GPT-4 Vision)
  /voice      - ØªØ­ÙˆÙŠÙ„ Ù†Øµ Ù„ÙƒÙ„Ø§Ù…
  /compare    - Ù…Ù‚Ø§Ø±Ù†Ø© Ø¨ÙŠÙ† 3 Ù†Ù…Ø§Ø°Ø¬
  /stream     - Ø¹Ø±Ø¶ Ø§Ù„Ø±Ø¯ Ù…Ø¨Ø§Ø´Ø±Ø© Ø£Ø«Ù†Ø§Ø¡ Ø§Ù„ÙƒØªØ§Ø¨Ø©

ğŸ“‹ Ø£ÙˆØ§Ù…Ø± Ø£Ø³Ø§Ø³ÙŠØ©:
  /models     - Ø§Ø®ØªÙŠØ§Ø± Ù†Ù…ÙˆØ°Ø¬ Ù…Ø®ØªÙ„Ù
  /search     - Ø¨Ø­Ø« ÙÙŠ Ø§Ù„Ø¥Ù†ØªØ±Ù†Øª
  /read       - Ù‚Ø±Ø§Ø¡Ø© Ù…Ù„Ù
  /write      - ÙƒØªØ§Ø¨Ø© Ù…Ù„Ù
  /analyze    - ØªØ­Ù„ÙŠÙ„ ÙƒÙˆØ¯
  /edit       - ØªØ¹Ø¯ÙŠÙ„ ÙƒÙˆØ¯

ğŸ’¡ Ù„Ù„Ø¯Ø±Ø¯Ø´Ø© Ø§Ù„Ø¹Ø§Ø¯ÙŠØ©: Ø§ÙƒØªØ¨ Ø³Ø¤Ø§Ù„Ùƒ Ù…Ø¨Ø§Ø´Ø±Ø©
                        """)

                    else:
                        print("âŒ Ø£Ù…Ø± ØºÙŠØ± Ù…Ø¹Ø±ÙˆÙ. Ø§ÙƒØªØ¨ /help Ù„Ù„Ù…Ø³Ø§Ø¹Ø¯Ø©")

                # Ø§Ù„Ø¯Ø±Ø¯Ø´Ø© Ø§Ù„Ø¹Ø§Ø¯ÙŠØ©
                else:
                    print(f"\nâ³ {self.models[self.current_model]['name']} ÙŠÙÙƒØ±...")
                    response = self.chat(user_input)
                    print(f"\nğŸ¤– {self.models[self.current_model]['name']}:\n{response}")

            except KeyboardInterrupt:
                print("\n\nğŸ‘‹ Ø¥Ù„Ù‰ Ø§Ù„Ù„Ù‚Ø§Ø¡!")
                break
            except Exception as e:
                print(f"\nâŒ Ø®Ø·Ø£: {str(e)}")


def main():
    """Ø§Ù„Ø¨Ø±Ù†Ø§Ù…Ø¬ Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠ"""
    try:
        from dotenv import load_dotenv
        load_dotenv()
    except:
        pass

    workspace = AIWorkspacePro()
    workspace.interactive_mode()


if __name__ == "__main__":
    main()
